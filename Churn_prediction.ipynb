{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LqZ_TFz3_In",
        "outputId": "5ddcebff-b822-4b5b-9176-a628d1cb3ee8"
      },
      "id": "7LqZ_TFz3_In",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7537acc",
      "metadata": {
        "id": "f7537acc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as ply\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve, classification_report, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split,cross_val_predict,StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from collections import  Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644edcac",
      "metadata": {
        "id": "644edcac"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Projects /churn prediction/train2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2cd565",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2cd565",
        "outputId": "4bba0ebf-26da-432c-f761-7ae3895685a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28382, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef32158c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef32158c",
        "outputId": "4664f768-c745-4d90-94e0-4c6402fac602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['customer_id', 'vintage', 'age', 'gender', 'dependents', 'occupation',\n",
              "       'city', 'customer_nw_category', 'branch_code', 'current_balance',\n",
              "       'previous_month_end_balance', 'average_monthly_balance_prevQ',\n",
              "       'average_monthly_balance_prevQ2', 'current_month_credit',\n",
              "       'previous_month_credit', 'current_month_debit', 'previous_month_debit',\n",
              "       'current_month_balance', 'previous_month_balance', 'churn',\n",
              "       'last_transaction'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34ecd1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d34ecd1b",
        "outputId": "ec72982a-aea3-4d5e-a7fd-6a463ed907e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23122\n",
              "1     5260\n",
              "Name: churn, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df[\"churn\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "476195cc",
      "metadata": {
        "id": "476195cc"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f486c70f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f486c70f",
        "outputId": "f4b89a09-dd7e-4243-cd52-6bd369662710"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id                          0\n",
              "vintage                              0\n",
              "age                                  0\n",
              "gender                             525\n",
              "dependents                        2463\n",
              "occupation                          80\n",
              "city                               803\n",
              "customer_nw_category                 0\n",
              "branch_code                          0\n",
              "current_balance                      0\n",
              "previous_month_end_balance           0\n",
              "average_monthly_balance_prevQ        0\n",
              "average_monthly_balance_prevQ2       0\n",
              "current_month_credit                 0\n",
              "previous_month_credit                0\n",
              "current_month_debit                  0\n",
              "previous_month_debit                 0\n",
              "current_month_balance                0\n",
              "previous_month_balance               0\n",
              "churn                                0\n",
              "last_transaction                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fce020",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "81fce020",
        "outputId": "aee16558-856f-4ce8-deba-ceccc129c345"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       customer_id  vintage  age  gender  dependents     occupation    city  \\\n",
              "0                1     2101   66    Male         0.0  self_employed   187.0   \n",
              "1                2     2348   35    Male         0.0  self_employed     NaN   \n",
              "2                4     2194   31    Male         0.0       salaried   146.0   \n",
              "3                5     2329   90     NaN         NaN  self_employed  1020.0   \n",
              "4                6     1579   42    Male         2.0  self_employed  1494.0   \n",
              "...            ...      ...  ...     ...         ...            ...     ...   \n",
              "28377        30297     2325   10  Female         0.0        student  1020.0   \n",
              "28378        30298     1537   34  Female         0.0  self_employed  1046.0   \n",
              "28379        30299     2376   47    Male         0.0       salaried  1096.0   \n",
              "28380        30300     1745   50    Male         3.0  self_employed  1219.0   \n",
              "28381        30301     1175   18    Male         0.0        student  1232.0   \n",
              "\n",
              "       customer_nw_category  branch_code  current_balance  ...  \\\n",
              "0                         2          755          1458.71  ...   \n",
              "1                         2         3214          5390.37  ...   \n",
              "2                         2           41          3913.16  ...   \n",
              "3                         2          582          2291.91  ...   \n",
              "4                         3          388           927.72  ...   \n",
              "...                     ...          ...              ...  ...   \n",
              "28377                     2         1207          1076.43  ...   \n",
              "28378                     2          223          3844.10  ...   \n",
              "28379                     2          588         65511.97  ...   \n",
              "28380                     3          274          1625.55  ...   \n",
              "28381                     2          474          2107.05  ...   \n",
              "\n",
              "       average_monthly_balance_prevQ  average_monthly_balance_prevQ2  \\\n",
              "0                            1458.71                         1449.07   \n",
              "1                            7799.26                        12419.41   \n",
              "2                            4910.17                         2815.94   \n",
              "3                            2084.54                         1006.54   \n",
              "4                            1643.31                         1871.12   \n",
              "...                              ...                             ...   \n",
              "28377                        2282.19                         2787.70   \n",
              "28378                        3668.83                         3865.55   \n",
              "28379                       53444.81                        21925.81   \n",
              "28380                        1683.20                         1857.42   \n",
              "28381                        3213.44                         4447.45   \n",
              "\n",
              "       current_month_credit  previous_month_credit  current_month_debit  \\\n",
              "0                      0.20                   0.20                 0.20   \n",
              "1                      0.56                   0.56              5486.27   \n",
              "2                      0.61                   0.61              6046.73   \n",
              "3                      0.47                   0.47                 0.47   \n",
              "4                      0.33                 714.61               588.62   \n",
              "...                     ...                    ...                  ...   \n",
              "28377                  0.30                   0.30                 0.30   \n",
              "28378                  1.71                   2.29               901.00   \n",
              "28379               4666.84                3883.06               168.23   \n",
              "28380                  0.20                   0.20                 0.20   \n",
              "28381                  0.11                   7.44               714.40   \n",
              "\n",
              "       previous_month_debit  current_month_balance  previous_month_balance  \\\n",
              "0                      0.20                1458.71                 1458.71   \n",
              "1                    100.56                6496.78                 8787.61   \n",
              "2                    259.23                5006.28                 5070.14   \n",
              "3                   2143.33                2291.91                 1669.79   \n",
              "4                   1538.06                1157.15                 1677.16   \n",
              "...                     ...                    ...                     ...   \n",
              "28377                  0.30                1076.43                 1076.43   \n",
              "28378               1014.07                3738.54                 3690.32   \n",
              "28379                 71.80               61078.50                57564.24   \n",
              "28380                  0.20                1625.55                 1625.55   \n",
              "28381               1094.09                2402.62                 3260.58   \n",
              "\n",
              "       churn  last_transaction  \n",
              "0          0        21-05-2019  \n",
              "1          0        01-11-2019  \n",
              "2          0               NaT  \n",
              "3          1        06-08-2019  \n",
              "4          1        03-11-2019  \n",
              "...      ...               ...  \n",
              "28377      0        22-10-2019  \n",
              "28378      0        17-12-2019  \n",
              "28379      1        31-12-2019  \n",
              "28380      0               NaT  \n",
              "28381      1        02-11-2019  \n",
              "\n",
              "[28382 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd67b843-6fc9-4bd9-8896-b5f91d713784\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>dependents</th>\n",
              "      <th>occupation</th>\n",
              "      <th>city</th>\n",
              "      <th>customer_nw_category</th>\n",
              "      <th>branch_code</th>\n",
              "      <th>current_balance</th>\n",
              "      <th>...</th>\n",
              "      <th>average_monthly_balance_prevQ</th>\n",
              "      <th>average_monthly_balance_prevQ2</th>\n",
              "      <th>current_month_credit</th>\n",
              "      <th>previous_month_credit</th>\n",
              "      <th>current_month_debit</th>\n",
              "      <th>previous_month_debit</th>\n",
              "      <th>current_month_balance</th>\n",
              "      <th>previous_month_balance</th>\n",
              "      <th>churn</th>\n",
              "      <th>last_transaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2101</td>\n",
              "      <td>66</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>187.0</td>\n",
              "      <td>2</td>\n",
              "      <td>755</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>...</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1449.07</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>0</td>\n",
              "      <td>21-05-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2348</td>\n",
              "      <td>35</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3214</td>\n",
              "      <td>5390.37</td>\n",
              "      <td>...</td>\n",
              "      <td>7799.26</td>\n",
              "      <td>12419.41</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>5486.27</td>\n",
              "      <td>100.56</td>\n",
              "      <td>6496.78</td>\n",
              "      <td>8787.61</td>\n",
              "      <td>0</td>\n",
              "      <td>01-11-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2194</td>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>salaried</td>\n",
              "      <td>146.0</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>3913.16</td>\n",
              "      <td>...</td>\n",
              "      <td>4910.17</td>\n",
              "      <td>2815.94</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>6046.73</td>\n",
              "      <td>259.23</td>\n",
              "      <td>5006.28</td>\n",
              "      <td>5070.14</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2329</td>\n",
              "      <td>90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>2</td>\n",
              "      <td>582</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>...</td>\n",
              "      <td>2084.54</td>\n",
              "      <td>1006.54</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>2143.33</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>1669.79</td>\n",
              "      <td>1</td>\n",
              "      <td>06-08-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>1579</td>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1494.0</td>\n",
              "      <td>3</td>\n",
              "      <td>388</td>\n",
              "      <td>927.72</td>\n",
              "      <td>...</td>\n",
              "      <td>1643.31</td>\n",
              "      <td>1871.12</td>\n",
              "      <td>0.33</td>\n",
              "      <td>714.61</td>\n",
              "      <td>588.62</td>\n",
              "      <td>1538.06</td>\n",
              "      <td>1157.15</td>\n",
              "      <td>1677.16</td>\n",
              "      <td>1</td>\n",
              "      <td>03-11-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28377</th>\n",
              "      <td>30297</td>\n",
              "      <td>2325</td>\n",
              "      <td>10</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>student</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1207</td>\n",
              "      <td>1076.43</td>\n",
              "      <td>...</td>\n",
              "      <td>2282.19</td>\n",
              "      <td>2787.70</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1076.43</td>\n",
              "      <td>1076.43</td>\n",
              "      <td>0</td>\n",
              "      <td>22-10-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28378</th>\n",
              "      <td>30298</td>\n",
              "      <td>1537</td>\n",
              "      <td>34</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1046.0</td>\n",
              "      <td>2</td>\n",
              "      <td>223</td>\n",
              "      <td>3844.10</td>\n",
              "      <td>...</td>\n",
              "      <td>3668.83</td>\n",
              "      <td>3865.55</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.29</td>\n",
              "      <td>901.00</td>\n",
              "      <td>1014.07</td>\n",
              "      <td>3738.54</td>\n",
              "      <td>3690.32</td>\n",
              "      <td>0</td>\n",
              "      <td>17-12-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28379</th>\n",
              "      <td>30299</td>\n",
              "      <td>2376</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>salaried</td>\n",
              "      <td>1096.0</td>\n",
              "      <td>2</td>\n",
              "      <td>588</td>\n",
              "      <td>65511.97</td>\n",
              "      <td>...</td>\n",
              "      <td>53444.81</td>\n",
              "      <td>21925.81</td>\n",
              "      <td>4666.84</td>\n",
              "      <td>3883.06</td>\n",
              "      <td>168.23</td>\n",
              "      <td>71.80</td>\n",
              "      <td>61078.50</td>\n",
              "      <td>57564.24</td>\n",
              "      <td>1</td>\n",
              "      <td>31-12-2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28380</th>\n",
              "      <td>30300</td>\n",
              "      <td>1745</td>\n",
              "      <td>50</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>3</td>\n",
              "      <td>274</td>\n",
              "      <td>1625.55</td>\n",
              "      <td>...</td>\n",
              "      <td>1683.20</td>\n",
              "      <td>1857.42</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1625.55</td>\n",
              "      <td>1625.55</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28381</th>\n",
              "      <td>30301</td>\n",
              "      <td>1175</td>\n",
              "      <td>18</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>student</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>2</td>\n",
              "      <td>474</td>\n",
              "      <td>2107.05</td>\n",
              "      <td>...</td>\n",
              "      <td>3213.44</td>\n",
              "      <td>4447.45</td>\n",
              "      <td>0.11</td>\n",
              "      <td>7.44</td>\n",
              "      <td>714.40</td>\n",
              "      <td>1094.09</td>\n",
              "      <td>2402.62</td>\n",
              "      <td>3260.58</td>\n",
              "      <td>1</td>\n",
              "      <td>02-11-2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28382 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd67b843-6fc9-4bd9-8896-b5f91d713784')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd67b843-6fc9-4bd9-8896-b5f91d713784 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd67b843-6fc9-4bd9-8896-b5f91d713784');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8442d29",
      "metadata": {
        "id": "a8442d29"
      },
      "outputs": [],
      "source": [
        "#Convert Gender\n",
        "dict_gender = {'Male': 1, 'Female':0}\n",
        "df.replace({'gender': dict_gender}, inplace = True)\n",
        "\n",
        "# Replace with -1 for missing gender\n",
        "df['gender'] = df['gender'].fillna(-1)\n",
        "\n",
        "# Replacing with max. occurence values\n",
        "df['dependents'] = df['dependents'].fillna(0)\n",
        "df['occupation'] = df['occupation'].fillna('self_employed')\n",
        "df['city'] = df['city'].fillna(1020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "636eb131",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "636eb131",
        "outputId": "4807f838-1ad4-43c5-8b79-bf55518ac2f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "self_employed    17556\n",
              "salaried          6704\n",
              "student           2058\n",
              "retired           2024\n",
              "company             40\n",
              "Name: occupation, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.occupation.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d248394b",
      "metadata": {
        "id": "d248394b"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df,pd.get_dummies(df['occupation'],prefix = str('occupation'),prefix_sep='_')],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06751271",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "06751271",
        "outputId": "40777b6c-9538-4bf6-da54-5ee5338aa551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customer_id  vintage  age  gender  dependents     occupation    city  \\\n",
              "0            1     2101   66     1.0         0.0  self_employed   187.0   \n",
              "1            2     2348   35     1.0         0.0  self_employed  1020.0   \n",
              "2            4     2194   31     1.0         0.0       salaried   146.0   \n",
              "3            5     2329   90    -1.0         0.0  self_employed  1020.0   \n",
              "4            6     1579   42     1.0         2.0  self_employed  1494.0   \n",
              "\n",
              "   customer_nw_category  branch_code  current_balance  ...  \\\n",
              "0                     2          755          1458.71  ...   \n",
              "1                     2         3214          5390.37  ...   \n",
              "2                     2           41          3913.16  ...   \n",
              "3                     2          582          2291.91  ...   \n",
              "4                     3          388           927.72  ...   \n",
              "\n",
              "   previous_month_debit  current_month_balance  previous_month_balance  churn  \\\n",
              "0                  0.20                1458.71                 1458.71      0   \n",
              "1                100.56                6496.78                 8787.61      0   \n",
              "2                259.23                5006.28                 5070.14      0   \n",
              "3               2143.33                2291.91                 1669.79      1   \n",
              "4               1538.06                1157.15                 1677.16      1   \n",
              "\n",
              "   last_transaction  occupation_company  occupation_retired  \\\n",
              "0        21-05-2019                   0                   0   \n",
              "1        01-11-2019                   0                   0   \n",
              "2               NaT                   0                   0   \n",
              "3        06-08-2019                   0                   0   \n",
              "4        03-11-2019                   0                   0   \n",
              "\n",
              "   occupation_salaried  occupation_self_employed  occupation_student  \n",
              "0                    0                         1                   0  \n",
              "1                    0                         1                   0  \n",
              "2                    1                         0                   0  \n",
              "3                    0                         1                   0  \n",
              "4                    0                         1                   0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1887423-dcdb-4a77-b7ff-8e09cbb0ac93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>dependents</th>\n",
              "      <th>occupation</th>\n",
              "      <th>city</th>\n",
              "      <th>customer_nw_category</th>\n",
              "      <th>branch_code</th>\n",
              "      <th>current_balance</th>\n",
              "      <th>...</th>\n",
              "      <th>previous_month_debit</th>\n",
              "      <th>current_month_balance</th>\n",
              "      <th>previous_month_balance</th>\n",
              "      <th>churn</th>\n",
              "      <th>last_transaction</th>\n",
              "      <th>occupation_company</th>\n",
              "      <th>occupation_retired</th>\n",
              "      <th>occupation_salaried</th>\n",
              "      <th>occupation_self_employed</th>\n",
              "      <th>occupation_student</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2101</td>\n",
              "      <td>66</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>187.0</td>\n",
              "      <td>2</td>\n",
              "      <td>755</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>0</td>\n",
              "      <td>21-05-2019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2348</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3214</td>\n",
              "      <td>5390.37</td>\n",
              "      <td>...</td>\n",
              "      <td>100.56</td>\n",
              "      <td>6496.78</td>\n",
              "      <td>8787.61</td>\n",
              "      <td>0</td>\n",
              "      <td>01-11-2019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2194</td>\n",
              "      <td>31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>salaried</td>\n",
              "      <td>146.0</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>3913.16</td>\n",
              "      <td>...</td>\n",
              "      <td>259.23</td>\n",
              "      <td>5006.28</td>\n",
              "      <td>5070.14</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2329</td>\n",
              "      <td>90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>2</td>\n",
              "      <td>582</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>...</td>\n",
              "      <td>2143.33</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>1669.79</td>\n",
              "      <td>1</td>\n",
              "      <td>06-08-2019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>1579</td>\n",
              "      <td>42</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1494.0</td>\n",
              "      <td>3</td>\n",
              "      <td>388</td>\n",
              "      <td>927.72</td>\n",
              "      <td>...</td>\n",
              "      <td>1538.06</td>\n",
              "      <td>1157.15</td>\n",
              "      <td>1677.16</td>\n",
              "      <td>1</td>\n",
              "      <td>03-11-2019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1887423-dcdb-4a77-b7ff-8e09cbb0ac93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1887423-dcdb-4a77-b7ff-8e09cbb0ac93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1887423-dcdb-4a77-b7ff-8e09cbb0ac93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "722ec544",
      "metadata": {
        "id": "722ec544"
      },
      "source": [
        "### Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c419e",
      "metadata": {
        "id": "241c419e"
      },
      "outputs": [],
      "source": [
        "#x = df.drop('Attrition', axis=1)\n",
        "x = df.drop(['churn','customer_id', 'occupation', 'last_transaction'], axis=1)\n",
        "y = df['churn']\n",
        "# Splitting the data into train and test\n",
        "X_train,X_test,y_train,y_test=train_test_split(x, y, train_size=0.8, stratify = y, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3dad07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3dad07",
        "outputId": "85753196-9def-4ebb-b697-0d71c2a7af97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((22705,), (5677,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae8db10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ae8db10",
        "outputId": "7f098892-3a96-4eb5-d1a3-00fd433a42db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.814691\n",
              "1    0.185309\n",
              "Name: churn, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "y_test.value_counts()/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886f867b",
      "metadata": {
        "id": "886f867b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "Scaler_X = StandardScaler()\n",
        "X_train = Scaler_X.fit_transform(X_train)\n",
        "X_test = Scaler_X.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b903c115",
      "metadata": {
        "id": "b903c115"
      },
      "source": [
        "### Handling class imbalance using SMOTE based techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f3bfce4",
      "metadata": {
        "id": "7f3bfce4"
      },
      "source": [
        "## SMOTE Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9baaf86f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9baaf86f",
        "outputId": "d3edd48b-b5d3-4928-b5b1-7c6b51991e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765e138c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "765e138c",
        "outputId": "a6f81405-fa46-4cfe-bb1e-8016a3d3f6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 18497, 1: 4208})\n",
            "After Counter({0: 18497, 1: 18497})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "counter = Counter(y_train)\n",
        "print('Before',counter)\n",
        "# oversampling the train dataset using SMOTE\n",
        "smt = SMOTE()\n",
        "#X_train, y_train = smt.fit_resample(X_train, y_train)\n",
        "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "counter = Counter(y_train_sm)\n",
        "print('After',counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) ADASYN Technique"
      ],
      "metadata": {
        "id": "b8ea3b05"
      },
      "id": "b8ea3b05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0558896f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0558896f",
        "outputId": "84f7a337-6fa4-4a8c-88d9-814599b4158d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 18497, 1: 4208})\n",
            "After Counter({0: 18497, 1: 18067})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "counter = Counter(y_train)\n",
        "print('Before',counter)\n",
        "# oversampling the train dataset using ADASYN\n",
        "ada = ADASYN(random_state=130)\n",
        "X_train_ada, y_train_ada = ada.fit_resample(X_train, y_train)\n",
        "\n",
        "counter = Counter(y_train_ada)\n",
        "print('After',counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) Hybrid Techniques"
      ],
      "metadata": {
        "id": "91fr6ei45e8_"
      },
      "id": "91fr6ei45e8_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + Tomek Links"
      ],
      "metadata": {
        "id": "ktn5GQLF5jFf"
      },
      "id": "ktn5GQLF5jFf"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "counter = Counter(y_train)\n",
        "print('Before',counter)\n",
        "# oversampling the train dataset using SMOTE + Tomek\n",
        "smtom = SMOTETomek(random_state=139)\n",
        "X_train_smtom, y_train_smtom = smtom.fit_resample(X_train, y_train)\n",
        "\n",
        "counter = Counter(y_train_smtom)\n",
        "print('After',counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3oo1jTl5n4I",
        "outputId": "96b29b2c-4afb-4e50-d83c-9d1c7b1f00b0"
      },
      "id": "r3oo1jTl5n4I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 18497, 1: 4208})\n",
            "After Counter({0: 18122, 1: 18122})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + ENN"
      ],
      "metadata": {
        "id": "CEmdk7M65p4J"
      },
      "id": "CEmdk7M65p4J"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "counter = Counter(y_train)\n",
        "print('Before',counter)\n",
        "# oversampling the train dataset using SMOTE + ENN\n",
        "smenn = SMOTEENN()\n",
        "X_train_smenn, y_train_smenn = smenn.fit_resample(X_train, y_train)\n",
        "\n",
        "counter = Counter(y_train_smenn)\n",
        "print('After',counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UMSht__5vPz",
        "outputId": "74bee23d-8585-4c9e-d14e-8a15a2d1dda8"
      },
      "id": "1UMSht__5vPz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 18497, 1: 4208})\n",
            "After Counter({1: 14811, 0: 9142})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building - Imbalanced data"
      ],
      "metadata": {
        "id": "0BqlfMq35xKq"
      },
      "id": "0BqlfMq35xKq"
    },
    {
      "cell_type": "code",
      "source": [
        "model = list()\n",
        "resample = list()\n",
        "precision = list()\n",
        "recall = list()\n",
        "F1score = list()\n",
        "AUCROC = list()"
      ],
      "metadata": {
        "id": "y1cgLi4k509p"
      },
      "id": "y1cgLi4k509p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_eval(clf_model, X_test, y_test, algo=None, sampling=None):\n",
        "    # Test set prediction\n",
        "    y_prob=clf_model.predict_proba(X_test)\n",
        "    y_pred=clf_model.predict(X_test)\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    print('='*60)\n",
        "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
        "    print('Classification Report')\n",
        "    print('='*60)\n",
        "    print(classification_report(y_test,y_pred),\"\\n\")\n",
        "    print('AUC-ROC')\n",
        "    print('='*60)\n",
        "    print(roc_auc_score(y_test, y_prob[:,1]))\n",
        "          \n",
        "    model.append(algo)\n",
        "    precision.append(precision_score(y_test,y_pred))\n",
        "    recall.append(recall_score(y_test,y_pred))\n",
        "    F1score.append(f1_score(y_test,y_pred))\n",
        "    AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
        "    resample.append(sampling)"
      ],
      "metadata": {
        "id": "LvgmwyH-53JH"
      },
      "id": "LvgmwyH-53JH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-1: Logistic Regression"
      ],
      "metadata": {
        "id": "_5g56DnF56SE"
      },
      "id": "_5g56DnF56SE"
    },
    {
      "cell_type": "code",
      "source": [
        "log_model=LogisticRegression()\n",
        "\n",
        "params={'C':np.logspace(-10, 1, 15),'class_weight':[None,'balanced'],'penalty':['l1','l2']}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
        "\n",
        "# Create grid search using 5-fold cross validation\n",
        "clf_LR = GridSearchCV(log_model, params, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "clf_LR.fit(X_train, y_train)\n",
        "clf_LR.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVeekcoU59ma",
        "outputId": "bbc3b94c-8740-497a-b4aa-cbdf1e9f6a03"
      },
      "id": "GVeekcoU59ma",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.58964275        nan 0.5895601         nan 0.58955997\n",
            "        nan 0.58955997        nan 0.58951196        nan 0.5895599\n",
            "        nan 0.58957923        nan 0.58956048        nan 0.58950933\n",
            "        nan 0.58955386        nan 0.58955397        nan 0.58951298\n",
            "        nan 0.58957749        nan 0.58929721        nan 0.58919936\n",
            "        nan 0.58934922        nan 0.59005065        nan 0.59768927\n",
            "        nan 0.6070709         nan 0.62968584        nan 0.65115708\n",
            "        nan 0.67998797        nan 0.70934622        nan 0.72002393\n",
            "        nan 0.74872056        nan 0.74314693        nan 0.7633858\n",
            "        nan 0.75101819        nan 0.76632924        nan 0.75283064]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'actual')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M78q9HMC5_Yq",
        "outputId": "df136989-9231-4bbb-9240-d65ff8024b9e"
      },
      "id": "M78q9HMC5_Yq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[4604   21]\n",
            " [ 968   84]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.90      4625\n",
            "           1       0.80      0.08      0.15      1052\n",
            "\n",
            "    accuracy                           0.83      5677\n",
            "   macro avg       0.81      0.54      0.52      5677\n",
            "weighted avg       0.82      0.83      0.76      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7719755420820059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE Resampling"
      ],
      "metadata": {
        "id": "oTK0_qfd6Do9"
      },
      "id": "oTK0_qfd6Do9"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR.fit(X_train_sm, y_train_sm)\n",
        "clf_LR.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB5SLFG76IpX",
        "outputId": "d540a2bd-458b-436d-958a-3ed9381ce071"
      },
      "id": "QB5SLFG76IpX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.58420816        nan 0.58419395        nan 0.5841994\n",
            "        nan 0.5841939         nan 0.58419427        nan 0.58419414\n",
            "        nan 0.58419533        nan 0.58419532        nan 0.58419452\n",
            "        nan 0.5841945         nan 0.58421305        nan 0.58422325\n",
            "        nan 0.58430304        nan 0.58429884        nan 0.58585339\n",
            "        nan 0.58585333        nan 0.59929478        nan 0.59929469\n",
            "        nan 0.64009011        nan 0.64008972        nan 0.69940977\n",
            "        nan 0.6994119         nan 0.74774532        nan 0.74774286\n",
            "        nan 0.77200304        nan 0.77193968        nan 0.78015988\n",
            "        nan 0.77974342        nan 0.78163047        nan 0.78163223]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0, class_weight='balanced')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YqL7yHb6LJu",
        "outputId": "72e0b2b1-11cc-43c1-bf2c-13a5981e3512"
      },
      "id": "-YqL7yHb6LJu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3656  969]\n",
            " [ 356  696]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.79      0.85      4625\n",
            "           1       0.42      0.66      0.51      1052\n",
            "\n",
            "    accuracy                           0.77      5677\n",
            "   macro avg       0.66      0.73      0.68      5677\n",
            "weighted avg       0.82      0.77      0.78      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7733741650395642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADASYN Resampling"
      ],
      "metadata": {
        "id": "8itIRfzs6W93"
      },
      "id": "8itIRfzs6W93"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR.fit(X_train_ada, y_train_ada)\n",
        "clf_LR.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpXhajer6bjD",
        "outputId": "9cfa0c03-2b83-4194-9353-bab1f1ee6961"
      },
      "id": "mpXhajer6bjD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.57397546        nan 0.57391272        nan 0.57394666\n",
            "        nan 0.57391259        nan 0.57393011        nan 0.57391286\n",
            "        nan 0.57397318        nan 0.57391189        nan 0.57390066\n",
            "        nan 0.57391118        nan 0.57390828        nan 0.57391352\n",
            "        nan 0.57393871        nan 0.57392922        nan 0.57534456\n",
            "        nan 0.57535281        nan 0.58824846        nan 0.58830804\n",
            "        nan 0.62966295        nan 0.62980423        nan 0.69768484\n",
            "        nan 0.69774808        nan 0.75335645        nan 0.75323524\n",
            "        nan 0.77959928        nan 0.77931303        nan 0.78714915\n",
            "        nan 0.78692223        nan 0.78890054        nan 0.78880044]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'adasyn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIDrvQTY6dwk",
        "outputId": "f7872053-1f4f-42e7-95ce-d307763fedbb"
      },
      "id": "mIDrvQTY6dwk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3735  890]\n",
            " [ 348  704]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86      4625\n",
            "           1       0.44      0.67      0.53      1052\n",
            "\n",
            "    accuracy                           0.78      5677\n",
            "   macro avg       0.68      0.74      0.69      5677\n",
            "weighted avg       0.83      0.78      0.80      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7770186003493987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + Tomek Resampling"
      ],
      "metadata": {
        "id": "PXC0aMYX6gpf"
      },
      "id": "PXC0aMYX6gpf"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR.fit(X_train_smtom, y_train_smtom)\n",
        "clf_LR.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPtUir226oVk",
        "outputId": "d2b2d8ac-9204-441a-945a-f0380e84b74a"
      },
      "id": "vPtUir226oVk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.58506963        nan 0.58503708        nan 0.58504526\n",
            "        nan 0.58503705        nan 0.58503743        nan 0.58503696\n",
            "        nan 0.58503765        nan 0.58503766        nan 0.58503981\n",
            "        nan 0.58503984        nan 0.58505511        nan 0.58506356\n",
            "        nan 0.5851705         nan 0.58517039        nan 0.58686677\n",
            "        nan 0.5868668         nan 0.60020992        nan 0.60020992\n",
            "        nan 0.64072183        nan 0.64072166        nan 0.70044929\n",
            "        nan 0.70045413        nan 0.74846703        nan 0.74848413\n",
            "        nan 0.77253042        nan 0.77257831        nan 0.77982628\n",
            "        nan 0.78000984        nan 0.78136356        nan 0.78144013]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0, class_weight='balanced')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote+tomek')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luH2prlq6qPy",
        "outputId": "8726a59e-ec87-49a9-c902-90889897dc1a"
      },
      "id": "luH2prlq6qPy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3634  991]\n",
            " [ 352  700]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.79      0.84      4625\n",
            "           1       0.41      0.67      0.51      1052\n",
            "\n",
            "    accuracy                           0.76      5677\n",
            "   macro avg       0.66      0.73      0.68      5677\n",
            "weighted avg       0.82      0.76      0.78      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7690897132874319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + ENN Resampling"
      ],
      "metadata": {
        "id": "Cfe-oTLU6sgU"
      },
      "id": "Cfe-oTLU6sgU"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_LR.fit(X_train_smenn, y_train_smenn)\n",
        "clf_LR.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCh04PjW6v5c",
        "outputId": "bf143073-79d3-4894-8805-c46f54f42f57"
      },
      "id": "yCh04PjW6v5c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.62322748        nan 0.62322947        nan 0.62323058\n",
            "        nan 0.62322955        nan 0.62322918        nan 0.62322955\n",
            "        nan 0.62322873        nan 0.62322873        nan 0.62322925\n",
            "        nan 0.62323139        nan 0.6232346         nan 0.62324912\n",
            "        nan 0.62334256        nan 0.62341694        nan 0.62465592\n",
            "        nan 0.62488159        nan 0.63559845        nan 0.63629424\n",
            "        nan 0.67240028        nan 0.673953          nan 0.73280466\n",
            "        nan 0.73476898        nan 0.78327923        nan 0.78505608\n",
            "        nan 0.80819504        nan 0.80964982        nan 0.81702053\n",
            "        nan 0.81832731        nan 0.81893368        nan 0.81994339]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0, class_weight='balanced')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote+enn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWY8KAYA60T4",
        "outputId": "a96fa484-7ea3-40ef-9825-3562451864d9"
      },
      "id": "mWY8KAYA60T4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3660  965]\n",
            " [ 344  708]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.79      0.85      4625\n",
            "           1       0.42      0.67      0.52      1052\n",
            "\n",
            "    accuracy                           0.77      5677\n",
            "   macro avg       0.67      0.73      0.68      5677\n",
            "weighted avg       0.82      0.77      0.79      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7706989004213339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-2: Decision Tree"
      ],
      "metadata": {
        "id": "4TInG1MT634x"
      },
      "id": "4TInG1MT634x"
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [2,10,30,50,100]\n",
        "# Maximum number of depth in each tree:\n",
        "max_depth = [i for i in range(5,16,2)]\n",
        "# Minimum number of samples to consider to split a node:\n",
        "min_samples_split = [2, 5, 10, 15, 20, 50, 100]\n",
        "# Minimum number of samples to consider at each leaf node:\n",
        "min_samples_leaf = [1, 2, 5]"
      ],
      "metadata": {
        "id": "kHGA8zn07ENq"
      },
      "id": "kHGA8zn07ENq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Original Unsampled Data"
      ],
      "metadata": {
        "id": "ZUPyc9DW7S96"
      },
      "id": "ZUPyc9DW7S96"
    },
    {
      "cell_type": "code",
      "source": [
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "tree_param_grid = { \n",
        "    'max_depth': max_depth,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'min_samples_leaf': min_samples_leaf\n",
        "}\n",
        "\n",
        "clf_DT = RandomizedSearchCV(tree_model, tree_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
        "clf_DT.fit(X_train, y_train)\n",
        "clf_DT.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGSQ3AvZ7Qc1",
        "outputId": "94a7e2d4-c17f-4981-9e17-89fa1f276272"
      },
      "id": "iGSQ3AvZ7Qc1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=9, min_samples_leaf=2, min_samples_split=100)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'actual')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DcRJZ7v7V0J",
        "outputId": "b5ded102-df4f-44dd-d917-efcf064031d9"
      },
      "id": "3DcRJZ7v7V0J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[4373  252]\n",
            " [ 580  472]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      4625\n",
            "           1       0.65      0.45      0.53      1052\n",
            "\n",
            "    accuracy                           0.85      5677\n",
            "   macro avg       0.77      0.70      0.72      5677\n",
            "weighted avg       0.84      0.85      0.84      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.8112984277052717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pqUXFOWU7YsC"
      },
      "id": "pqUXFOWU7YsC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE Resampling"
      ],
      "metadata": {
        "id": "1Y55RTh27kEv"
      },
      "id": "1Y55RTh27kEv"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_DT.fit(X_train_sm, y_train_sm)\n",
        "clf_DT.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubpveyrc7oqE",
        "outputId": "4f8ef4e7-803c-4466-9df8-f7b50f4a8e24"
      },
      "id": "Ubpveyrc7oqE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=13, min_samples_split=100)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT08yTRs7rYM",
        "outputId": "4ac0e1cd-9094-4067-d865-6b03bac6ad64"
      },
      "id": "GT08yTRs7rYM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3593 1032]\n",
            " [ 363  689]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.78      0.84      4625\n",
            "           1       0.40      0.65      0.50      1052\n",
            "\n",
            "    accuracy                           0.75      5677\n",
            "   macro avg       0.65      0.72      0.67      5677\n",
            "weighted avg       0.81      0.75      0.77      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7710543623471381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.ADASYN Resampling"
      ],
      "metadata": {
        "id": "PGOg2xKu7wXm"
      },
      "id": "PGOg2xKu7wXm"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf_DT.fit(X_train_ada, y_train_ada)\n",
        "clf_DT.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218PKkLU7xal",
        "outputId": "340ce620-37d8-43e2-f109-76eebaca4cd3"
      },
      "id": "218PKkLU7xal",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=9, min_samples_leaf=5, min_samples_split=20)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'adasyn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ySFvYI71ja",
        "outputId": "04c9916d-0f9d-4322-e8ee-d62bafb0732e"
      },
      "id": "b0ySFvYI71ja",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3673  952]\n",
            " [ 349  703]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.79      0.85      4625\n",
            "           1       0.42      0.67      0.52      1052\n",
            "\n",
            "    accuracy                           0.77      5677\n",
            "   macro avg       0.67      0.73      0.68      5677\n",
            "weighted avg       0.82      0.77      0.79      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7903254547322989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + Tomek Resampling"
      ],
      "metadata": {
        "id": "8vuiJ6on76Y4"
      },
      "id": "8vuiJ6on76Y4"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_DT.fit(X_train_smtom, y_train_smtom)\n",
        "clf_DT.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soRyGFqF73Nz",
        "outputId": "713f02ac-5fc7-44ab-f736-045790687129"
      },
      "id": "soRyGFqF73Nz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=7, min_samples_leaf=5, min_samples_split=100)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote+tomek')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjJsGfPE8AW3",
        "outputId": "ca7a1bc6-a340-41b5-866a-797aaadb21c0"
      },
      "id": "bjJsGfPE8AW3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3610 1015]\n",
            " [ 337  715]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.78      0.84      4625\n",
            "           1       0.41      0.68      0.51      1052\n",
            "\n",
            "    accuracy                           0.76      5677\n",
            "   macro avg       0.66      0.73      0.68      5677\n",
            "weighted avg       0.82      0.76      0.78      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7972124139348474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + ENN Resampling"
      ],
      "metadata": {
        "id": "S4RvW1c38CcZ"
      },
      "id": "S4RvW1c38CcZ"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_DT.fit(X_train_smenn, y_train_smenn)\n",
        "clf_DT.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmvJUeeX8MXC",
        "outputId": "d52d6205-bf0c-4969-8ddb-52b75967037a"
      },
      "id": "FmvJUeeX8MXC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=11, min_samples_leaf=5, min_samples_split=100)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote+enn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPolonGR8OkD",
        "outputId": "258d683c-20a0-4180-aeac-5e8f9e8c5fee"
      },
      "id": "DPolonGR8OkD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3082 1543]\n",
            " [ 254  798]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.67      0.77      4625\n",
            "           1       0.34      0.76      0.47      1052\n",
            "\n",
            "    accuracy                           0.68      5677\n",
            "   macro avg       0.63      0.71      0.62      5677\n",
            "weighted avg       0.82      0.68      0.72      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7844987154454834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-3: Random Forest"
      ],
      "metadata": {
        "id": "CgmAW4IS8Q86"
      },
      "id": "CgmAW4IS8Q86"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Unsampled Data"
      ],
      "metadata": {
        "id": "LeZ4cITn8WFk"
      },
      "id": "LeZ4cITn8WFk"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "rf_params={'n_estimators':estimators,\n",
        "           'max_depth':max_depth,\n",
        "           'min_samples_split':min_samples_split}\n",
        "\n",
        "clf_RF = RandomizedSearchCV(rf_model, rf_params, cv=cv, scoring='roc_auc', n_jobs=-1, n_iter=20, verbose=2)\n",
        "clf_RF.fit(X_train, y_train)\n",
        "clf_RF.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mBPDn-Z8YZn",
        "outputId": "2208ba83-4c7c-48ef-e7a7-fc7552b639cd"
      },
      "id": "8mBPDn-Z8YZn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, min_samples_split=50, n_estimators=30)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'actual')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpEhOsve8cch",
        "outputId": "0d0537e2-9ee5-4e44-dfc5-a41352f36bb6"
      },
      "id": "MpEhOsve8cch",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[4463  162]\n",
            " [ 602  450]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      4625\n",
            "           1       0.74      0.43      0.54      1052\n",
            "\n",
            "    accuracy                           0.87      5677\n",
            "   macro avg       0.81      0.70      0.73      5677\n",
            "weighted avg       0.85      0.87      0.85      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.837576713595725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE Resampling"
      ],
      "metadata": {
        "id": "4HcWP5BT8edb"
      },
      "id": "4HcWP5BT8edb"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RF.fit(X_train_sm, y_train_sm)\n",
        "clf_RF.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx_MCSgX8heG",
        "outputId": "986be104-91c8-467b-d8d8-4e758d7ac5d5"
      },
      "id": "sx_MCSgX8heG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=13, min_samples_split=20, n_estimators=50)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv3pJqE_8iz6",
        "outputId": "c9b38e39-b3bc-49a8-e177-f1ddcd0c4702"
      },
      "id": "Nv3pJqE_8iz6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3781  844]\n",
            " [ 316  736]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87      4625\n",
            "           1       0.47      0.70      0.56      1052\n",
            "\n",
            "    accuracy                           0.80      5677\n",
            "   macro avg       0.69      0.76      0.71      5677\n",
            "weighted avg       0.84      0.80      0.81      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.8181325660261021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADASYN Resampling"
      ],
      "metadata": {
        "id": "n8FP39_I8kYr"
      },
      "id": "n8FP39_I8kYr"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RF.fit(X_train_ada, y_train_ada)\n",
        "clf_RF.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-O0PAma8prt",
        "outputId": "f4be120c-e8e7-456d-b1fb-28a2856dc880"
      },
      "id": "b-O0PAma8prt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, min_samples_split=5, n_estimators=30)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'adasyn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpfpYApk8rHF",
        "outputId": "e4f2b926-8bb1-46db-d98b-075fc7bc0f29"
      },
      "id": "jpfpYApk8rHF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3859  766]\n",
            " [ 334  718]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.83      0.88      4625\n",
            "           1       0.48      0.68      0.57      1052\n",
            "\n",
            "    accuracy                           0.81      5677\n",
            "   macro avg       0.70      0.76      0.72      5677\n",
            "weighted avg       0.84      0.81      0.82      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.8186552255677731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + Tomek Resampling"
      ],
      "metadata": {
        "id": "EyerrfVf8s2B"
      },
      "id": "EyerrfVf8s2B"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RF.fit(X_train_smtom, y_train_smtom)\n",
        "clf_RF.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jphxu_e8vqN",
        "outputId": "8260f9e8-0ba1-40b8-98f0-b89ee8c5f6e8"
      },
      "id": "4jphxu_e8vqN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, min_samples_split=15)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote+tomek')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rkmlJV78xnc",
        "outputId": "66722378-aca1-42d3-acc5-9728b6024fe6"
      },
      "id": "3rkmlJV78xnc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3825  800]\n",
            " [ 323  729]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.83      0.87      4625\n",
            "           1       0.48      0.69      0.56      1052\n",
            "\n",
            "    accuracy                           0.80      5677\n",
            "   macro avg       0.70      0.76      0.72      5677\n",
            "weighted avg       0.84      0.80      0.82      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.8213400472716063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + ENN Resampling"
      ],
      "metadata": {
        "id": "ag1fCNf280VH"
      },
      "id": "ag1fCNf280VH"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RF.fit(X_train_smenn, y_train_smenn)\n",
        "clf_RF.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfyROOjK83z4",
        "outputId": "6d0ec496-5652-4c22-c27b-a2426ac1916c"
      },
      "id": "LfyROOjK83z4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=10)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote+enn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Exm4St885QS",
        "outputId": "0213e791-042c-4f40-a394-ec0236093a35"
      },
      "id": "9Exm4St885QS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "============================================================\n",
            "[[3245 1380]\n",
            " [ 247  805]] \n",
            "\n",
            "Classification Report\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80      4625\n",
            "           1       0.37      0.77      0.50      1052\n",
            "\n",
            "    accuracy                           0.71      5677\n",
            "   macro avg       0.65      0.73      0.65      5677\n",
            "weighted avg       0.83      0.71      0.74      5677\n",
            " \n",
            "\n",
            "AUC-ROC\n",
            "============================================================\n",
            "0.7991156099064844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Comparision"
      ],
      "metadata": {
        "id": "2edh0gyl86p5"
      },
      "id": "2edh0gyl86p5"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_eval_df = pd.DataFrame({'model':model,\n",
        "                            'resample':resample,\n",
        "                            'precision':precision,\n",
        "                            'recall':recall,\n",
        "                            'f1-score':F1score,\n",
        "                            'AUC-ROC':AUCROC})"
      ],
      "metadata": {
        "id": "LPbndV_k883Z"
      },
      "id": "LPbndV_k883Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_eval_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "JnJ6Qy9d9BTH",
        "outputId": "0cad6ff2-3194-4962-b0f5-ea482cb4277a"
      },
      "id": "JnJ6Qy9d9BTH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model     resample  precision    recall  f1-score   AUC-ROC\n",
              "0   Logistic Regression       actual   0.800000  0.079848  0.145203  0.771976\n",
              "1   Logistic Regression        smote   0.418018  0.661597  0.512330  0.773374\n",
              "2   Logistic Regression       adasyn   0.441656  0.669202  0.532124  0.777019\n",
              "3   Logistic Regression  smote+tomek   0.413956  0.665399  0.510390  0.769090\n",
              "4   Logistic Regression    smote+enn   0.423192  0.673004  0.519633  0.770699\n",
              "5         Decision Tree       actual   0.651934  0.448669  0.531532  0.811298\n",
              "6         Decision Tree        smote   0.400349  0.654943  0.496935  0.771054\n",
              "7         Decision Tree       adasyn   0.424773  0.668251  0.519394  0.790325\n",
              "8         Decision Tree  smote+tomek   0.413295  0.679658  0.514019  0.797212\n",
              "9         Decision Tree    smote+enn   0.340880  0.758555  0.470380  0.784499\n",
              "10        Random Forest       actual   0.735294  0.427757  0.540865  0.837577\n",
              "11        Random Forest        smote   0.465823  0.699620  0.559271  0.818133\n",
              "12        Random Forest       adasyn   0.483827  0.682510  0.566246  0.818655\n",
              "13        Random Forest  smote+tomek   0.476782  0.692966  0.564897  0.821340\n",
              "14        Random Forest    smote+enn   0.368421  0.765209  0.497374  0.799116"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1384d3c-52ff-41a5-9182-ede0f6dc440c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>resample</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>AUC-ROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>actual</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.079848</td>\n",
              "      <td>0.145203</td>\n",
              "      <td>0.771976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>smote</td>\n",
              "      <td>0.418018</td>\n",
              "      <td>0.661597</td>\n",
              "      <td>0.512330</td>\n",
              "      <td>0.773374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>adasyn</td>\n",
              "      <td>0.441656</td>\n",
              "      <td>0.669202</td>\n",
              "      <td>0.532124</td>\n",
              "      <td>0.777019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>smote+tomek</td>\n",
              "      <td>0.413956</td>\n",
              "      <td>0.665399</td>\n",
              "      <td>0.510390</td>\n",
              "      <td>0.769090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>smote+enn</td>\n",
              "      <td>0.423192</td>\n",
              "      <td>0.673004</td>\n",
              "      <td>0.519633</td>\n",
              "      <td>0.770699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>actual</td>\n",
              "      <td>0.651934</td>\n",
              "      <td>0.448669</td>\n",
              "      <td>0.531532</td>\n",
              "      <td>0.811298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>smote</td>\n",
              "      <td>0.400349</td>\n",
              "      <td>0.654943</td>\n",
              "      <td>0.496935</td>\n",
              "      <td>0.771054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>adasyn</td>\n",
              "      <td>0.424773</td>\n",
              "      <td>0.668251</td>\n",
              "      <td>0.519394</td>\n",
              "      <td>0.790325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>smote+tomek</td>\n",
              "      <td>0.413295</td>\n",
              "      <td>0.679658</td>\n",
              "      <td>0.514019</td>\n",
              "      <td>0.797212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>smote+enn</td>\n",
              "      <td>0.340880</td>\n",
              "      <td>0.758555</td>\n",
              "      <td>0.470380</td>\n",
              "      <td>0.784499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>actual</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.427757</td>\n",
              "      <td>0.540865</td>\n",
              "      <td>0.837577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>smote</td>\n",
              "      <td>0.465823</td>\n",
              "      <td>0.699620</td>\n",
              "      <td>0.559271</td>\n",
              "      <td>0.818133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>adasyn</td>\n",
              "      <td>0.483827</td>\n",
              "      <td>0.682510</td>\n",
              "      <td>0.566246</td>\n",
              "      <td>0.818655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>smote+tomek</td>\n",
              "      <td>0.476782</td>\n",
              "      <td>0.692966</td>\n",
              "      <td>0.564897</td>\n",
              "      <td>0.821340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>smote+enn</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.765209</td>\n",
              "      <td>0.497374</td>\n",
              "      <td>0.799116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1384d3c-52ff-41a5-9182-ede0f6dc440c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1384d3c-52ff-41a5-9182-ede0f6dc440c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1384d3c-52ff-41a5-9182-ede0f6dc440c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=1.2)\n",
        "#sns.palplot(sns.color_palette())\n",
        "g = sns.FacetGrid(clf_eval_df, col=\"model\", height=5)\n",
        "g.map(sns.barplot, \"resample\", \"recall\", palette='twilight', order=[\"actual\", \"smote\", \"adasyn\", \"smote+tomek\", \"smote+enn\"])\n",
        "g.set_xticklabels(rotation=30)\n",
        "g.set_xlabels(' ', fontsize=14)\n",
        "g.set_ylabels('Recall', fontsize=14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "zcDsVacg9DA9",
        "outputId": "de8a8793-b549-4d54-bfb4-d95919cc46b5"
      },
      "id": "zcDsVacg9DA9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fe6f25ff790>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_X08uK2_9FKH"
      },
      "id": "_X08uK2_9FKH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Churn prediction.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}